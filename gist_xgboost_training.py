import numpy as np
import pandas as pd
import re
import os
import json
from joblib import dump, load
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def concat_feature(feather_folder_path):
    avclass = ['fareit', 'hidelink', 'loic', 'ramnit', 'faceliker', 'coinhive', 'iframeinject', 'fbjack', 'fakejquery', 'scrinject', 'refresh', 'prepscram', 'cryxos', 'iframeref', 'virut', 'inor', 'redir', 'phish', 'submelius', 'blacole', 'zusy', 'smsreg', 'wapomi', 'cryptscript', 'c99shell']
    all_feature = pd.DataFrame()
    label_index = 0
    for av in avclass:
        feature_path = os.path.join(feather_folder_path, f"{av}.feather")
        df = pd.read_feather(feature_path)
        df["label"] = label_index
        all_feature = pd.concat([all_feature, df])
        label_index += 1
    all_feature.reset_index(drop=True, inplace=True)
    all_feature.to_feather(feather_folder_path + "\\all_feature.feather")


if __name__ == "__main__":
    # training data with xgboost
    feather_folder_path = "D:\\pth\\malwares_feature"
    all_feature = pd.read_feather(feather_folder_path + "all_feature.feather")
    X = all_feature.drop("label", axis=1)
    y = all_feature["label"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    xgb_model = xgb.XGBClassifier(
        objective="multi:softmax",
        num_class=25,
        n_estimators=400,
        max_depth=36,
    )
    # eval_set = [(X_train, y_train), (X_test, y_test)]
    xgb_model.fit(X_train, y_train, eval_metric="mlogloss", verbose=True)
    y_pred = xgb_model.predict(X_test)
    print("The accuracy of xgbClassifier is : ", accuracy_score(y_test, y_pred.round())*100, "%")
    print("The precision of xgbClassifier is : ", precision_score(y_test, y_pred.round(), average=None)*100, "%")
    print("The recall of xgbClassifier is : ", recall_score(y_test, y_pred.round(), average=None)*100, "%")
    print("The f1 of xgbClassifier is : ", f1_score(y_test, y_pred.round(), average=None)*100, "%")
    dump(xgb_model, './model_xgb.joblib')
    print('\n--------------- Classification Report ---------------\n')
    print(classification_report(y_test, y_pred))
    print('---------------------- XGBoost ----------------------') # unnecessary fancy styling