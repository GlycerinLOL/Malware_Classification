import torch
from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop, Grayscale
from datasets import load_dataset
from Model import MalwareCNN
import warnings

from flwr_datasets.partitioner import IidPartitioner


warnings.filterwarnings("ignore")


def load_partition(partition_id, toy: bool = False):
    """Load partition local data."""
    fds = load_dataset('imagefolder', data_dir='datasets/pcap_gray_img_15')
    partitioner = IidPartitioner(num_partitions=3)
    partitioner.dataset = fds['train']
    partition = partitioner.load_partition(partition_id)
    # Divide data on each node: 70% train, 30% test
    partition_train_test = partition.train_test_split(test_size=0.3, seed=42)
    partition_train_test = partition_train_test.with_transform(apply_transforms)
    print(f"Loaded partition {partition_id}")
    return partition_train_test["train"], partition_train_test["test"]


def load_centralized_data():
    fds = load_dataset('imagefolder', data_dir='datasets/pcap_gray_img_15')
    fds = fds['train'].train_test_split(test_size=0.3, seed=42)
    centralized_data = fds['test']
    centralized_data = centralized_data.with_transform(apply_transforms)
    return centralized_data


def apply_transforms(batch):
    """Apply transforms to the partition from FederatedDataset."""
    transform = Compose([
        Resize((40, 40)),
        Grayscale(),
        ToTensor(),
    ])
    batch["image"] = [transform(img) for img in batch["image"]]
    return batch


def train(
    net, trainloader, valloader, epochs, device: torch.device = torch.device("cpu")
):
    """Train the network on the training set."""
    print("Starting training...")
    net.to(device)  # move model to GPU if available
    criterion = torch.nn.CrossEntropyLoss().to(device)
    # optimizer = torch.optim.SGD(
    #     net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4
    # )
    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)
    net.train()
    for _ in range(epochs):
        for batch in trainloader:
            images, labels = batch["image"], batch["label"]
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            loss = criterion(net(images), labels)
            loss.backward()
            optimizer.step()

    net.to("cpu")  # move model back to CPU

    train_loss, train_acc = test(net, trainloader)
    val_loss, val_acc = test(net, valloader)

    results = {
        "train_loss": train_loss,
        "train_accuracy": train_acc,
        "val_loss": val_loss,
        "val_accuracy": val_acc,
    }
    return results


def test(
    net, testloader, steps: int = None, device: torch.device = torch.device("cpu")
):
    """Validate the network on the entire test set."""
    print("Starting evalutation...")
    net.to(device)  # move model to GPU if available
    criterion = torch.nn.CrossEntropyLoss()
    correct, loss = 0, 0.0
    net.eval()
    with torch.no_grad():
        for batch_idx, batch in enumerate(testloader):
            images, labels = batch["image"], batch["label"]
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            loss += criterion(outputs, labels).item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            if steps is not None and batch_idx == steps:
                break
    accuracy = correct / len(testloader.dataset)
    net.to("cpu")  # move model back to CPU
    return loss, accuracy


def get_model_params(model):
    """Returns a model's parameters."""
    return [val.cpu().numpy() for _, val in model.state_dict().items()]


def load_model(num_classes):
    return MalwareCNN(num_classes=num_classes)
