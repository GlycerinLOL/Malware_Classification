import torch
from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop, Grayscale
from datasets import load_dataset
from Model import MalwareCNN
import warnings
from tqdm import tqdm

from flwr_datasets.partitioner import IidPartitioner


warnings.filterwarnings("ignore")

class utilities():
    def __init__(
        self, 
        datapath: str = 'datasets/pcap_gray_img_15',
        num_partition: int = 3,
        optimizer: str = 'adam'
        ):
        self.datapath = datapath
        self.num_partition = num_partition
        self.optim = optimizer

    def load_partition(self, partition_id, toy: bool = False):
        """Load partition local data."""
        fds = load_dataset('imagefolder', data_dir=self.datapath)
        partitioner = IidPartitioner(num_partitions=self.num_partition)
        partitioner.dataset = fds['train']
        if self.num_partition == 1:
            ds = partitioner.load_partition(0)
        else:
            ds = partitioner.load_partition(partition_id)
        # Divide data on each node: 70% train, 30% test
        partition_train_test = ds.train_test_split(test_size=0.3, seed=42)
        partition_train_test = partition_train_test.with_transform(self.apply_transforms)
        print(f"Loaded partition {partition_id}")
        return partition_train_test["train"], partition_train_test["test"]


    def load_centralized_data(self):
        fds = load_dataset('imagefolder', data_dir=self.datapath)
        fds = fds['train'].train_test_split(test_size=0.3, seed=42)
        centralized_data = fds['test']
        centralized_data = centralized_data.with_transform(self.apply_transforms)
        return centralized_data


    def apply_transforms(self, batch):
        """Apply transforms to the partition from FederatedDataset."""
        transform = Compose([
            Resize((60, 60)),
            Grayscale(),
            ToTensor(),
        ])
        batch["image"] = [transform(img) for img in batch["image"]]
        return batch


    def train(
        self, net, trainloader, valloader, epochs, device: torch.device = torch.device("cpu")
    ):
        """Train the network on the training set."""
        print("Starting training...")
        net.to(device)  # move model to GPU if available
        criterion = torch.nn.CrossEntropyLoss().to(device)
        if self.optim == 'adam':
            optimizer = torch.optim.Adam(net.parameters(), lr=0.001)
        elif self.optim == 'sgd':
            optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)
        net.train()
        for _ in range(epochs):
            print("Epoch: ", _)
            for batch in tqdm(trainloader):
                images, labels = batch["image"], batch["label"]
                images, labels = images.to(device), labels.to(device)
                optimizer.zero_grad()
                loss = criterion(net(images), labels)
                loss.backward()
                optimizer.step()

        net.to("cpu")  # move model back to CPU

        train_loss, train_acc = self.test(net, trainloader)
        val_loss, val_acc = self.test(net, valloader)

        results = {
            "train_loss": train_loss,
            "train_accuracy": train_acc,
            "val_loss": val_loss,
            "val_accuracy": val_acc,
        }
        return results


    def test(
        self, net, testloader, steps: int = None, device: torch.device = torch.device("cpu")
    ):
        """Validate the network on the entire test set."""
        print("Starting evalutation...")
        net.to(device)  # move model to GPU if available
        criterion = torch.nn.CrossEntropyLoss()
        correct, loss = 0, 0.0
        net.eval()
        with torch.no_grad():
            for batch_idx, batch in enumerate(tqdm(testloader)):
                images, labels = batch["image"], batch["label"]
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                loss += criterion(outputs, labels).item()
                _, predicted = torch.max(outputs.data, 1)
                correct += (predicted == labels).sum().item()
                if steps is not None and batch_idx == steps:
                    break
        accuracy = correct / len(testloader.dataset)
        net.to("cpu")  # move model back to CPU
        return loss, accuracy


    def get_model_params(self, model):
        """Returns a model's parameters."""
        return [val.cpu().numpy() for _, val in model.state_dict().items()]


    def load_model(self, num_classes):
        return MalwareCNN(num_classes=num_classes)
        # return MalwareCNNModel3(num_classes=num_classes)
