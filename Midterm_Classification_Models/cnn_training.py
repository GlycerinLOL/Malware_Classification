import torch
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from Model import MalwareCNNModel3
from tqdm import tqdm
import datetime
import warnings
from log_config import setup_logging
warnings.filterwarnings('ignore')


# folder = 'datasets/malimg_paper_dataset_imgs'
# folder = 'datasets/virusShare'
folder = 'datasets/malwares_images_virus31320'
ds_name = 'malwares_images_virus31320'
# model_save_path = 'ckpt/malimg/best_model_f1.pth'
# model_save_path = 'ckpt/virusShare/best_model_f1.pth'
model_save_path = 'ckpt/malwares_images_virus31320/best_model_f1.pth'
num_epochs = 10
train_p = 0.7

# Current date and time for the log file name
current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
log_filename = f'cnn_log/{ds_name}/training_log_{current_time}.log'

logger = setup_logging(log_file=log_filename)
logger.info(f'Number of epochs: {num_epochs}, Data folder: {folder}')

# Dataset Preparation
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.Grayscale(),
    transforms.ToTensor(),
])
dataset = ImageFolder(root=folder, transform=transform)

num_classes = len(dataset.classes)

# Splitting dataset
train_size = int(train_p * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Model, Loss, and Optimizer
model = MalwareCNNModel3(num_classes=num_classes).to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Set the interval (steps) at which you want to observe the loss
log_interval = 100  # For example, log the loss every 100 steps

best_val_f1 = 0.0  # Initialize the best F1 score to a low value

for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    # Use enumerate to get the step number within each epoch
    train_loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)
    for step, (images, labels) in train_loop:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

        # Check if the current step is a multiple of the log_interval
        if step % log_interval == 0 and step > 0:
            current_loss = total_loss / log_interval
            logger.info(f'Epoch: {epoch+1}, Step: {step}, Loss: {current_loss}')
            # Reset total_loss to zero after logging
            total_loss = 0

        # Update tqdm progress bar description
        train_loop.set_description(f"Epoch {epoch+1}/{num_epochs}")
        train_loop.set_postfix(loss=loss.item())
        
    # Validation phase
    model.eval()
    val_preds = []
    val_labels = []
    val_total_loss = 0
    val_loop = tqdm(enumerate(val_loader), total=len(val_loader), leave=True)
    with torch.no_grad():
        for step, (images, labels) in val_loop:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_total_loss += loss.item()
            
            _, predicted = torch.max(outputs, 1)
            val_preds.extend(predicted.cpu().numpy())
            val_labels.extend(labels.cpu().numpy())

            val_loop.set_description(f"Validation Epoch {epoch+1}/{num_epochs}")
            val_loop.set_postfix(loss=loss.item())

    # Calculating metrics
    val_accuracy = accuracy_score(val_labels, val_preds)
    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='weighted')
    avg_val_loss = val_total_loss / len(val_loader)
    
    logger.info(f'Validation - Epoch: {epoch+1}, Avg Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1 Score: {val_f1:.4f}')
    
    if val_f1 > best_val_f1:
        best_val_f1 = val_f1
        torch.save(model.state_dict(), model_save_path)
        logger.info(f'Model improved and saved at epoch {epoch+1}: F1 Score = {best_val_f1:.4f}')
    else:
        logger.info(f'No improvement in F1 Score at epoch {epoch+1}: Best F1 Score = {best_val_f1:.4f}')
