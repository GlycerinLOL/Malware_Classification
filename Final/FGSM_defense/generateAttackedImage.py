# 1. load dataset from D:\code\Malware_Classification\datasets\malwares_images_virus31320
# 2. randomly select 500 images from each class, if the class has less than 500 images, select all images
# 3. generate adversarial images for each image with epsilon = 0.01 with FGSM
# 4. save the adversarial images to D:\code\Malware_Classification\datasets\malwares_images_virus31320_adv

import cv2
import numpy as np
import os
from PIL import Image
from pathlib import Path
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
import matplotlib.pyplot as plt
from CNN_Model import MalwareCNNModel3
from tqdm import tqdm

pretrained_model = "D:\\code\\Malware_Classification\\Model\\best_model_f1_20240528.pth"
folder = "D:\\code\\Malware_Classification\\datasets\\malwares_images_virus31320"
imgSaveFolder = "D:\\code\\Malware_Classification\\datasets\\targetDataset"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.Grayscale(),
    transforms.ToTensor(),
])

# dataset = ImageFolder(root=folder, transform=transform)
dataset = ImageFolder(root=folder)
data_loader = DataLoader(dataset, batch_size=1, shuffle=True)

# split the dataset into training and validation
val_size = int(0.3 * len(dataset))
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)



num_classes = 26
model = MalwareCNNModel3(num_classes).to(device)
model.load_state_dict(torch.load(pretrained_model, map_location=device))
model.eval()

malClasses = [
    "benign",
    "blacole",
    "c99shell",
    "coinhive",
    "cryptscript",
    "cryxos",
    "faceliker",
    "fakejquery",
    "fareit",
    "fbjack",
    "hidelink",
    "iframeinject",
    "iframeref",
    "inor",
    "loic",
    "phish",
    "prepscram",
    "ramnit",
    "redir",
    "refresh",
    "scrinject",
    "smsreg",
    "submelius",
    "virut",
    "wapomi",
    "zusy"
]

# FGSM attack code
def fgsm_attack(image, epsilon, data_grad):
    sign_data_grad = data_grad.sign()
    perturbed_image = image + epsilon*sign_data_grad
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    
    return perturbed_image

def denorm(batch, mean=[0.1307], std=[0.3081]):
    if isinstance(mean, list):
        mean = torch.tensor(mean).to(device)
    if isinstance(std, list):
        std = torch.tensor(std).to(device)

    return batch * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)

def genAdversarialImage( model, device, data_loader, epsilon ):
    for data, target in tqdm(data_loader):
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        output = model(data)
        init_pred = output.max(1, keepdim=True)[1]
        if init_pred.item() != target.item():
            continue
        loss = F.nll_loss(output, target)
        model.zero_grad()
        loss.backward()
        data_grad = data.grad.data
        data_denorm = denorm(data)
        # Call FGSM Attack
        perturbed_data = fgsm_attack(data_denorm, epsilon, data_grad)
        ret_img = perturbed_data.squeeze().detach().cpu().numpy()

        # save the adversarial image
        random_name = str(np.random.randint(1000000))
        img = Image.fromarray((ret_img*255).astype(np.uint8))
        img.save(imgSaveFolder + "\\" + malClasses[target.item()] + "\\" + random_name + "_adv.png")

def saveDataset( dataLoader ):
    for data, target in tqdm(dataLoader):
        data = data.squeeze().detach().cpu().numpy()
        name = str(len(list(Path(imgSaveFolder + "\\" + malClasses[target.item()]).glob("*"))) + 1)
        img = Image.fromarray((data*255).astype(np.uint8))
        img.save(imgSaveFolder + "\\" + malClasses[target.item()] + "\\" + name + ".png")

if __name__ == "__main__":
    for malClass in malClasses:
        os.makedirs(imgSaveFolder + "\\" + malClass, exist_ok=True)
    genAdversarialImage(model, device, val_dataloader, 0.01)