# Final Project - Adversarial Attack
## Intro
- Adversarial Attack
    - FGSM
    - Iterative FGSM
    - Posion Attack: One Shot Kill Attack
- Defense
    - Passive: Gaussian Blur
    - Proactive: Adversarial Training

## Folder Information
- `BinaryToImage`: generate image from binary
- `FGSM`: implement FGSM Attack
- `FGSM_defense`: implement two defenses, Passive Defense and Proactive Defense
    - `generateAttackedImage.py`: use pretrained model and FGSM to generate adversarial image from dataset
- `IFGSM`: implement Iterative FGSM
- `PoisonFrogs`: implement Poison Attack with One Shot Kill Attack

## Pretrained Model
- [One Drive Link](https://mailntustedutw-my.sharepoint.com/personal/b11015030_ms_ntust_edu_tw/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fb11015030%5Fms%5Fntust%5Fedu%5Ftw%2FDocuments%2F%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8%E5%B0%8E%E8%AB%96%2FModel)
    - `best_model_f1.pth`: without Adversarial Training
    - `best_model_f1_20240605_0.pth`: Adversarial Training with 20% of original dataset
    - `best_model_f1_20240605_1.pth`: Adversarial Training with 50% of original dataset