import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt
from CNN_Model import MalwareCNNModel3
from tqdm import tqdm
from PIL import Image
import pandas as pd

epsilons = [0, .05]
pretrained_model = "D:\\code\\Malware_Classification\\Model\\best_model_f1_20240528.pth"
folder = "D:\\code\\Malware_Classification\\datasets\\testDataset"
use_cuda=True
torch.manual_seed(42)

# classes
malClasses = [
    "benign",
    "blacole",
    "c99shell",
    "coinhive",
    "cryptscript",
    "cryxos",
    "faceliker",
    "fakejquery",
    "fareit",
    "fbjack",
    "hidelink",
    "iframeinject",
    "iframeref",
    "inor",
    "loic",
    "phish",
    "prepscram",
    "ramnit",
    "redir",
    "refresh",
    "scrinject",
    "smsreg",
    "submelius",
    "virut",
    "wapomi",
    "zusy"
]

# Dataset Preparation
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.Grayscale(),
    transforms.ToTensor(),
])
dataset = ImageFolder(root=folder, transform=transform)
test_loader = DataLoader(dataset, batch_size=1, shuffle=True)
num_classes = 26

# Define what device we are using
print("CUDA Available: ",torch.cuda.is_available())
device = torch.device("cuda" if use_cuda and torch.cuda.is_available() else "cpu")

# Initialize the network
model = MalwareCNNModel3(num_classes).to(device)

# Load the pretrained model
model.load_state_dict(torch.load(pretrained_model, map_location=device))

# Set the model in evaluation mode. In this case this is for the Dropout layers
model.eval()


# Iterative FGSM attack code
def ifgsm_attack(image, epsilon, data_grad):
    iter = 10
    alpha = epsilon / iter
    perturbed_image = image
    for i in range(iter):
        sign_data_grad = data_grad.sign()
        perturbed_image = perturbed_image + alpha*sign_data_grad
        image = torch.clamp(image, 0, 1)
        if torch.norm((perturbed_image - image), p=float('inf')) > epsilon:
            break
    return perturbed_image

# restores the tensors to their original scale
def denorm(batch, mean=[0.1307], std=[0.3081]):
    """
    Convert a batch of tensors to their original scale.

    Args:
        batch (torch.Tensor): Batch of normalized tensors.
        mean (torch.Tensor or list): Mean used for normalization.
        std (torch.Tensor or list): Standard deviation used forcr normalization.

    Returns:
        torch.Tensor: batch of tensors without normalization applied to them.
    """
    if isinstance(mean, list):
        mean = torch.tensor(mean).to(device)
    if isinstance(std, list):
        std = torch.tensor(std).to(device)

    return batch * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)

def test( model, device, test_loader, y_target=None, epsilon=0 ):

    successful_attack = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        y_target = y_target.to(device)
        data.requires_grad = True
        output = model(data)
        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability

        # Calculate the loss
        loss = -F.cross_entropy(output, y_target)
        model.zero_grad()
        loss.backward()
        data_grad = data.grad.data
        data_denorm = denorm(data)

        perturbed_data = ifgsm_attack(data_denorm, epsilon, data_grad)
        perturbed_data_normalized = transforms.Normalize((0.1307,), (0.3081,))(perturbed_data)
        output = model(perturbed_data_normalized)

        # Check for success
        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability

        if epsilon == 0:
            if final_pred.item() == target.item():
                successful_attack += 1
                if len(adv_examples) < 8:
                    adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                    adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )
        else:
            if final_pred.item() == y_target.item():
                successful_attack += 1
                if len(adv_examples) < 8:
                    adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                    adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )

    final_acc = successful_attack/float(len(test_loader))
    print(f"Epsilon: {epsilon}\tsuccessful Accuracy = {successful_attack} / {len(test_loader)} = {final_acc}")
    return final_acc, adv_examples


if __name__ == "__main__":
    accuracies = []
    examples = []
    
    col = [0, 0.05]
    result = pd.DataFrame(columns=[0, 0.05])
    for t in tqdm(range(0, 26)):
        y_target = torch.tensor([t])
        # Run test for each epsilon
        acc_value = []
        for eps in (epsilons):
            acc, ex = test(model, device, test_loader, y_target, eps)
            accuracies.append(acc)
            acc_value.append(round(acc*100, 2))
        result.loc[malClasses[t]] = acc_value

    print(result)
    result.to_csv("targeted_attack_result.csv")