{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian92308/env/ENTER/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "dataset = load_from_disk(\"datasets/labeled_data_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = dataset.train_test_split(test_size=0.2)\n",
    "_split = split['test'].train_test_split(test_size=0.5)\n",
    "train_ds = split['train']\n",
    "val_ds = _split['train']\n",
    "test_ds = _split['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {id:label for id, label in enumerate(train_ds.features['label'].names)}\n",
    "label2id = {label:id for id,label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    ToTensor)\n",
    "\n",
    "image_mean, image_std = processor.image_mean, processor.image_std\n",
    "size = processor.size[\"height\"]\n",
    "\n",
    "normalize = Normalize(mean=image_mean, std=image_std)\n",
    "_train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "_val_transforms = Compose(\n",
    "        [\n",
    "            Resize(size),\n",
    "            CenterCrop(size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def train_transforms(examples):\n",
    "    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def val_transforms(examples):\n",
    "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the transforms\n",
    "train_ds.set_transform(train_transforms)\n",
    "val_ds.set_transform(val_transforms)\n",
    "test_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "\n",
    "# model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', id2label=id2label, label2id=label2id)\n",
    "config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k', label2id=label2id, id2label=id2label)\n",
    "model = ViTForImageClassification(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint detected, resuming training at test-malware_classification/checkpoint-2688. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return dict(accuracy=accuracy_score(predictions, labels))\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"test-malware_classification\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=30,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=200,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")\n",
    "\n",
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(args.output_dir):\n",
    "    last_checkpoint = get_last_checkpoint(args.output_dir)\n",
    "    if last_checkpoint is not None:\n",
    "        print(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8400' max='8400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8400/8400 2:13:46, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.321100</td>\n",
       "      <td>3.202507</td>\n",
       "      <td>0.310680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>3.321100</td>\n",
       "      <td>3.134486</td>\n",
       "      <td>0.359223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>3.321100</td>\n",
       "      <td>3.163199</td>\n",
       "      <td>0.352751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>3.321100</td>\n",
       "      <td>3.259803</td>\n",
       "      <td>0.343042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>3.321100</td>\n",
       "      <td>3.187015</td>\n",
       "      <td>0.368932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.321100</td>\n",
       "      <td>3.333126</td>\n",
       "      <td>0.330097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.321100</td>\n",
       "      <td>3.218460</td>\n",
       "      <td>0.346278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.183146</td>\n",
       "      <td>0.362460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.328691</td>\n",
       "      <td>0.330097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.324489</td>\n",
       "      <td>0.313916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.226770</td>\n",
       "      <td>0.349515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.255715</td>\n",
       "      <td>0.336570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.242377</td>\n",
       "      <td>0.352751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.227333</td>\n",
       "      <td>0.349515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.296506</td>\n",
       "      <td>0.336570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.223366</td>\n",
       "      <td>0.343042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.249716</td>\n",
       "      <td>0.343042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.250026</td>\n",
       "      <td>0.349515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.294187</td>\n",
       "      <td>0.349515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.198513</td>\n",
       "      <td>0.359223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.277503</td>\n",
       "      <td>0.336570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.206679</td>\n",
       "      <td>0.381877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.203219</td>\n",
       "      <td>0.372168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.138430</td>\n",
       "      <td>0.365696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.251645</td>\n",
       "      <td>0.362460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.276548</td>\n",
       "      <td>0.336570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.196863</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.225126</td>\n",
       "      <td>0.355987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.245825</td>\n",
       "      <td>0.359223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.264851</td>\n",
       "      <td>0.343042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.971300</td>\n",
       "      <td>3.167406</td>\n",
       "      <td>0.359223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.193267</td>\n",
       "      <td>0.362460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.172279</td>\n",
       "      <td>0.359223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.221967</td>\n",
       "      <td>0.362460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.197994</td>\n",
       "      <td>0.359223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.159335</td>\n",
       "      <td>0.388350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.181265</td>\n",
       "      <td>0.385113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.183416</td>\n",
       "      <td>0.378641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.135863</td>\n",
       "      <td>0.368932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.131776</td>\n",
       "      <td>0.381877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.202216</td>\n",
       "      <td>0.375405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.243404</td>\n",
       "      <td>0.368932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>2.704700</td>\n",
       "      <td>3.158134</td>\n",
       "      <td>0.391586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.142305</td>\n",
       "      <td>0.394822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.160624</td>\n",
       "      <td>0.391586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.101527</td>\n",
       "      <td>0.401294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.091736</td>\n",
       "      <td>0.368932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.094748</td>\n",
       "      <td>0.388350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.143946</td>\n",
       "      <td>0.375405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.161270</td>\n",
       "      <td>0.375405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.108576</td>\n",
       "      <td>0.414239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.115958</td>\n",
       "      <td>0.385113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.069712</td>\n",
       "      <td>0.420712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.097764</td>\n",
       "      <td>0.391586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>2.486800</td>\n",
       "      <td>3.090896</td>\n",
       "      <td>0.385113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.112045</td>\n",
       "      <td>0.381877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.090365</td>\n",
       "      <td>0.378641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.085746</td>\n",
       "      <td>0.394822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.055818</td>\n",
       "      <td>0.401294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.085576</td>\n",
       "      <td>0.401294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.099334</td>\n",
       "      <td>0.391586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.114682</td>\n",
       "      <td>0.385113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.067749</td>\n",
       "      <td>0.394822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.076950</td>\n",
       "      <td>0.411003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.071774</td>\n",
       "      <td>0.411003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>3.112712</td>\n",
       "      <td>0.375405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.082340</td>\n",
       "      <td>0.414239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.058641</td>\n",
       "      <td>0.404531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.024670</td>\n",
       "      <td>0.401294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.063891</td>\n",
       "      <td>0.401294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.081477</td>\n",
       "      <td>0.398058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.075957</td>\n",
       "      <td>0.404531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.016691</td>\n",
       "      <td>0.430421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.015959</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.015037</td>\n",
       "      <td>0.427184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.035283</td>\n",
       "      <td>0.417476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.073896</td>\n",
       "      <td>0.427184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>3.065980</td>\n",
       "      <td>0.414239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.017950</td>\n",
       "      <td>0.414239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>2.973472</td>\n",
       "      <td>0.430421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.025746</td>\n",
       "      <td>0.433657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.026442</td>\n",
       "      <td>0.427184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>2.989597</td>\n",
       "      <td>0.430421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.021962</td>\n",
       "      <td>0.443366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.005206</td>\n",
       "      <td>0.417476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.025557</td>\n",
       "      <td>0.427184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>2.998227</td>\n",
       "      <td>0.446602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.027429</td>\n",
       "      <td>0.423948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.013438</td>\n",
       "      <td>0.440129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>3.006097</td>\n",
       "      <td>0.443366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.961200</td>\n",
       "      <td>0.440129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.980072</td>\n",
       "      <td>0.430421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.982650</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.993923</td>\n",
       "      <td>0.423948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.993630</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>3.004229</td>\n",
       "      <td>0.433657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.980674</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.987732</td>\n",
       "      <td>0.443366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.975625</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.952724</td>\n",
       "      <td>0.462783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.996378</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>2.961749</td>\n",
       "      <td>0.459547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.955373</td>\n",
       "      <td>0.453074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.964996</td>\n",
       "      <td>0.453074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.964975</td>\n",
       "      <td>0.433657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.962764</td>\n",
       "      <td>0.446602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.967532</td>\n",
       "      <td>0.446602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.964849</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.974514</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.963678</td>\n",
       "      <td>0.443366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.939861</td>\n",
       "      <td>0.446602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.938913</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.951772</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.845400</td>\n",
       "      <td>2.953202</td>\n",
       "      <td>0.456311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.938423</td>\n",
       "      <td>0.475728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.941255</td>\n",
       "      <td>0.462783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.926173</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.923594</td>\n",
       "      <td>0.462783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.922067</td>\n",
       "      <td>0.466019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.911999</td>\n",
       "      <td>0.466019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.927198</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.925517</td>\n",
       "      <td>0.456311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.924122</td>\n",
       "      <td>0.453074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.919777</td>\n",
       "      <td>0.443366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.917874</td>\n",
       "      <td>0.456311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.770500</td>\n",
       "      <td>2.903836</td>\n",
       "      <td>0.466019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.921000</td>\n",
       "      <td>0.456311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.912033</td>\n",
       "      <td>0.462783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.916529</td>\n",
       "      <td>0.456311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.922636</td>\n",
       "      <td>0.456311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.913662</td>\n",
       "      <td>0.459547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.919159</td>\n",
       "      <td>0.449838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.918745</td>\n",
       "      <td>0.459547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.918441</td>\n",
       "      <td>0.453074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.916568</td>\n",
       "      <td>0.462783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>2.916745</td>\n",
       "      <td>0.462783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8400, training_loss=1.503825465611049, metrics={'train_runtime': 8034.2312, 'train_samples_per_second': 61.636, 'train_steps_per_second': 1.046, 'total_flos': 3.854600041828516e+19, 'train_loss': 1.503825465611049, 'epoch': 200.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 2.990150213241577, 'test_accuracy': 0.44516129032258067, 'test_runtime': 8.8161, 'test_samples_per_second': 35.163, 'test_steps_per_second': 4.424}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在目前儲存格或上一個儲存格中執行程式碼時，Kernel 已損毀。\n",
      "\u001b[1;31m請檢閱儲存格中的程式碼，找出失敗的可能原因。\n",
      "\u001b[1;31m如需詳細資訊，請按一下<a href='https://aka.ms/vscodeJupyterKernelCrash'>這裡</a>。\n",
      "\u001b[1;31m如需詳細資料，請檢視 Jupyter <a href='command:jupyter.viewOutput'>記錄</a>。"
     ]
    }
   ],
   "source": [
    "outputs = trainer.predict(test_ds)\n",
    "print(outputs.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
